#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TikTok Bot - C·∫£i thi·ªán hi·ªáu qu·∫£ skip v·ªõi Eye Movement Extension
Enhanced with realistic eye movement animations for background overlay
"""

import os
import time
import logging
import json
import math
import threading
from typing import List, Optional, Tuple
import random

# Try to import advanced libraries, fallback to basic implementation
try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("‚ö†Ô∏è OpenCV kh√¥ng kh·∫£ d·ª•ng - s·ª≠ d·ª•ng implementation c∆° b·∫£n")

try:
    import subprocess
    SUBPROCESS_AVAILABLE = True
except ImportError:
    SUBPROCESS_AVAILABLE = False

class RealisticEyeMovement:
    """
    H·ªá th·ªëng chuy·ªÉn ƒë·ªông m·∫Øt ch√¢n th·∫≠t cho background extension
    T·∫°o chuy·ªÉn ƒë·ªông m·∫Øt m∆∞·ª£t m√† v√† t·ª± nhi√™n
    """
    
    def __init__(self):
        print("üëÅÔ∏è Kh·ªüi t·∫°o Realistic Eye Movement System...")
        
        # C·∫•u h√¨nh chuy·ªÉn ƒë·ªông m·∫Øt
        self.eye_config = {
            "movement_smoothness": 0.08,    # ƒê·ªô m∆∞·ª£t chuy·ªÉn ƒë·ªông (0.01-0.5)
            "pupil_dilation_base": 1.0,     # K√≠ch th∆∞·ªõc ƒë·ªìng t·ª≠ c∆° b·∫£n  
            "blink_frequency": 3.5,         # T·∫ßn s·ªë nh√°y m·∫Øt (gi√¢y)
            "micro_movement_range": 0.15,   # Ph·∫°m vi chuy·ªÉn ƒë·ªông nh·ªè t·ª± nhi√™n
            "saccade_speed": 0.25,          # T·ªëc ƒë·ªô di chuy·ªÉn nhanh
            "natural_drift": 0.03,          # Tr√¥i ch·∫≠m t·ª± nhi√™n
            "focus_tracking": True,         # Theo d√µi ti√™u ƒëi·ªÉm
            "realistic_physics": True,      # √Åp d·ª•ng v·∫≠t l√Ω ch√¢n th·∫≠t
        }
        
        # Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa m·∫Øt
        self.current_state = {
            "gaze_x": 0.0,           # H∆∞·ªõng nh√¨n X (-1 ƒë·∫øn 1)
            "gaze_y": 0.0,           # H∆∞·ªõng nh√¨n Y (-1 ƒë·∫øn 1)
            "target_x": 0.0,         # M·ª•c ti√™u X
            "target_y": 0.0,         # M·ª•c ti√™u Y
            "pupil_dilation": 1.0,   # ƒê·ªô gi√£n ƒë·ªìng t·ª≠ (0.5-1.8)
            "blink_state": 1.0,      # Tr·∫°ng th√°i nh√°y m·∫Øt (0=ƒë√≥ng, 1=m·ªü)
            "attention_level": 1.0,   # M·ª©c ƒë·ªô t·∫≠p trung (0-1)
            "fatigue_level": 0.0,    # M·ª©c ƒë·ªô m·ªát m·ªèi (0-1)
        }
        
        # Timing controls
        self.timing = {
            "last_blink": time.time(),
            "last_micro_movement": time.time(),
            "last_gaze_change": time.time(),
            "last_attention_change": time.time(),
        }
        
        # Animation state
        self.is_active = False
        self.is_blinking = False
        
        # Statistics
        self.stats = {
            "total_blinks": 0,
            "gaze_changes": 0,
            "smooth_movements": 0,
            "session_start": time.time()
        }
        
        print("‚úÖ Eye Movement System initialized")
    
    def calculate_natural_blink_interval(self):
        """T√≠nh to√°n kho·∫£ng th·ªùi gian nh√°y m·∫Øt t·ª± nhi√™n"""
        base_interval = self.eye_config["blink_frequency"]
        
        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n m·ª©c ƒë·ªô m·ªát m·ªèi
        fatigue_factor = 1 - (self.current_state["fatigue_level"] * 0.3)
        
        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n m·ª©c ƒë·ªô t·∫≠p trung
        attention_factor = 0.8 + (self.current_state["attention_level"] * 0.4)
        
        # Th√™m random variation
        random_factor = random.uniform(0.7, 1.3)
        
        return base_interval * fatigue_factor * attention_factor * random_factor
    
    def generate_smooth_movement(self):
        """T·∫°o chuy·ªÉn ƒë·ªông m·∫Øt m∆∞·ª£t m√† v√† t·ª± nhi√™n"""
        current_time = time.time()
        
        # Smooth interpolation to target
        smoothness = self.eye_config["movement_smoothness"]
        
        # Apply realistic physics - kh√¥ng di chuy·ªÉn qu√° nhanh
        max_change_per_frame = 0.05
        
        # Calculate movement towards target
        dx = self.current_state["target_x"] - self.current_state["gaze_x"]
        dy = self.current_state["target_y"] - self.current_state["gaze_y"]
        
        # Limit movement speed for realism
        movement_x = max(-max_change_per_frame, min(max_change_per_frame, dx * smoothness))
        movement_y = max(-max_change_per_frame, min(max_change_per_frame, dy * smoothness))
        
        # Apply movement
        self.current_state["gaze_x"] += movement_x
        self.current_state["gaze_y"] += movement_y
        
        # Add micro movements for realism
        if current_time - self.timing["last_micro_movement"] > 0.8:
            micro_range = self.eye_config["micro_movement_range"]
            micro_x = random.uniform(-micro_range, micro_range) * 0.3
            micro_y = random.uniform(-micro_range, micro_range) * 0.3
            
            self.current_state["target_x"] += micro_x
            self.current_state["target_y"] += micro_y
            
            # Keep within bounds
            self.current_state["target_x"] = max(-1, min(1, self.current_state["target_x"]))
            self.current_state["target_y"] = max(-1, min(1, self.current_state["target_y"]))
            
            self.timing["last_micro_movement"] = current_time
            self.stats["smooth_movements"] += 1
    
    def update_pupil_dilation(self):
        """C·∫≠p nh·∫≠t ƒë·ªô gi√£n ƒë·ªìng t·ª≠ d·ª±a tr√™n c√°c y·∫øu t·ªë t·ª± nhi√™n"""
        # Base dilation
        base = self.eye_config["pupil_dilation_base"]
        
        # Attention affects pupil size
        attention_effect = self.current_state["attention_level"] * 0.3
        
        # Fatigue affects pupil size  
        fatigue_effect = self.current_state["fatigue_level"] * 0.2
        
        # Random variation for realism
        random_variation = random.uniform(-0.05, 0.05)
        
        # Calculate new dilation
        new_dilation = base + attention_effect - fatigue_effect + random_variation
        
        # Smooth transition
        current_dilation = self.current_state["pupil_dilation"]
        smooth_factor = 0.02
        self.current_state["pupil_dilation"] = (
            current_dilation * (1 - smooth_factor) + new_dilation * smooth_factor
        )
        
        # Keep within realistic bounds
        self.current_state["pupil_dilation"] = max(0.5, min(1.8, self.current_state["pupil_dilation"]))
    
    def trigger_natural_blink(self):
        """K√≠ch ho·∫°t nh√°y m·∫Øt t·ª± nhi√™n"""
        if self.is_blinking:
            return
            
        self.is_blinking = True
        self.stats["total_blinks"] += 1
        
        def blink_animation():
            """Animation nh√°y m·∫Øt m∆∞·ª£t m√†"""
            blink_duration = 0.15  # 150ms
            frames = 8
            frame_time = blink_duration / frames
            
            # Close eyes
            for i in range(frames // 2):
                progress = i / (frames // 2)
                self.current_state["blink_state"] = 1.0 - progress
                time.sleep(frame_time)
            
            # Open eyes  
            for i in range(frames // 2):
                progress = i / (frames // 2)
                self.current_state["blink_state"] = progress
                time.sleep(frame_time)
            
            self.current_state["blink_state"] = 1.0
            self.is_blinking = False
        
        # Run blink animation in separate thread
        threading.Thread(target=blink_animation, daemon=True).start()
    
    def set_gaze_target(self, x: float, y: float, speed_multiplier: float = 1.0):
        """
        Thi·∫øt l·∫≠p m·ª•c ti√™u h∆∞·ªõng nh√¨n m·ªõi
        x, y: T·ªça ƒë·ªô m·ª•c ti√™u (-1 ƒë·∫øn 1)
        speed_multiplier: H·ªá s·ªë t·ªëc ƒë·ªô (1.0 = b√¨nh th∆∞·ªùng)
        """
        self.current_state["target_x"] = max(-1, min(1, x))
        self.current_state["target_y"] = max(-1, min(1, y))
        
        self.stats["gaze_changes"] += 1
        self.timing["last_gaze_change"] = time.time()
        
        # Adjust movement speed if needed
        if speed_multiplier != 1.0:
            self.eye_config["movement_smoothness"] *= speed_multiplier
    
    def generate_natural_gaze_pattern(self):
        """T·∫°o pattern h∆∞·ªõng nh√¨n t·ª± nhi√™n"""
        current_time = time.time()
        
        # Change gaze target periodically
        if current_time - self.timing["last_gaze_change"] > random.uniform(4, 12):
            # Natural looking patterns
            patterns = [
                # Looking around naturally
                (random.uniform(-0.8, 0.8), random.uniform(-0.6, 0.6)),
                # Focus on center occasionally
                (random.uniform(-0.2, 0.2), random.uniform(-0.2, 0.2)),
                # Look at specific areas of interest
                (random.uniform(0.3, 0.7), random.uniform(-0.3, 0.3)),
                (-random.uniform(0.3, 0.7), random.uniform(-0.3, 0.3)),
            ]
            
            target_x, target_y = random.choice(patterns)
            self.set_gaze_target(target_x, target_y)
    
    def update_attention_and_fatigue(self):
        """C·∫≠p nh·∫≠t m·ª©c ƒë·ªô t·∫≠p trung v√† m·ªát m·ªèi"""
        current_time = time.time()
        
        if current_time - self.timing["last_attention_change"] > 30:  # Every 30 seconds
            # Simulate natural attention fluctuation
            attention_change = random.uniform(-0.1, 0.1)
            self.current_state["attention_level"] = max(0.3, min(1.0, 
                self.current_state["attention_level"] + attention_change))
            
            # Gradual fatigue increase
            fatigue_increase = random.uniform(0.001, 0.005)
            self.current_state["fatigue_level"] = min(0.8, 
                self.current_state["fatigue_level"] + fatigue_increase)
            
            self.timing["last_attention_change"] = current_time
    
    def update_animation_frame(self):
        """C·∫≠p nh·∫≠t m·ªôt frame c·ªßa animation"""
        if not self.is_active:
            return
            
        current_time = time.time()
        
        # Update all eye movement components
        self.generate_smooth_movement()
        self.update_pupil_dilation()
        self.generate_natural_gaze_pattern()
        self.update_attention_and_fatigue()
        
        # Handle natural blinking
        blink_interval = self.calculate_natural_blink_interval()
        if current_time - self.timing["last_blink"] > blink_interval:
            self.trigger_natural_blink()
            self.timing["last_blink"] = current_time
    
    def get_eye_data(self) -> dict:
        """L·∫•y d·ªØ li·ªáu tr·∫°ng th√°i m·∫Øt hi·ªán t·∫°i"""
        return {
            "gaze": {
                "x": self.current_state["gaze_x"],
                "y": self.current_state["gaze_y"]
            },
            "pupil_dilation": self.current_state["pupil_dilation"],
            "blink_state": self.current_state["blink_state"],
            "attention_level": self.current_state["attention_level"],
            "fatigue_level": self.current_state["fatigue_level"]
        }
    
    def start_animation(self):
        """B·∫Øt ƒë·∫ßu animation m·∫Øt"""
        self.is_active = True
        print("üëÅÔ∏è Eye animation started")
    
    def stop_animation(self):
        """D·ª´ng animation m·∫Øt"""
        self.is_active = False
        print("üëÅÔ∏è Eye animation stopped")
    
    def print_eye_stats(self):
        """In th·ªëng k√™ eye movement"""
        runtime = time.time() - self.stats["session_start"]
        print(f"\nüëÅÔ∏è EYE MOVEMENT STATS:")
        print(f"   Runtime: {runtime:.1f}s")
        print(f"   Total blinks: {self.stats['total_blinks']}")
        print(f"   Gaze changes: {self.stats['gaze_changes']}")
        print(f"   Smooth movements: {self.stats['smooth_movements']}")
        print(f"   Current attention: {self.current_state['attention_level']:.2f}")
        print(f"   Current fatigue: {self.current_state['fatigue_level']:.2f}")

def safe_import():
    """Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt"""
    modules = {}
    
    try:
        import pyautogui
        pyautogui.FAILSAFE = False
        pyautogui.PAUSE = 0.1  # Gi·∫£m pause time
        modules['pyautogui'] = pyautogui
        print("‚úÖ pyautogui: OK")
    except ImportError:
        print("‚ùå pyautogui: MISSING")
        modules['pyautogui'] = None
    
    try:
        import pygetwindow as gw
        modules['pygetwindow'] = gw
        print("‚úÖ pygetwindow: OK")
    except ImportError:
        print("‚ùå pygetwindow: MISSING")
        modules['pygetwindow'] = None
    
    try:
        import pytesseract
        import platform
        if platform.system() == "Windows":
            paths = [
                r'C:\Program Files\Tesseract-OCR\tesseract.exe',
                r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe'
            ]
            for path in paths:
                if os.path.exists(path):
                    pytesseract.pytesseract.tesseract_cmd = path
                    break
        
        pytesseract.get_tesseract_version()
        modules['pytesseract'] = pytesseract
        print("‚úÖ pytesseract: OK")
    except:
        print("‚ùå pytesseract: ERROR")
        modules['pytesseract'] = None
    
    return modules

class ImprovedTikTokBot:
    def __init__(self):
        print("üöÄ Kh·ªüi t·∫°o TikTok Bot Improved v·ªõi Eye Movement Extension...")
        
        self.modules = safe_import()
        
        # Initialize Eye Movement System
        self.eye_movement = RealisticEyeMovement()
        
        # C·∫•u h√¨nh skip methods v·ªõi ƒë·ªô ∆∞u ti√™n
        self.skip_methods = [
            {
                "name": "enhanced_keyboard", 
                "priority": 1, 
                "enabled": True,
                "success_rate": 0.0,
                "attempts": 0,
                "successes": 0
            },
            {
                "name": "mouse_swipe_up", 
                "priority": 2, 
                "enabled": True,
                "success_rate": 0.0,
                "attempts": 0,
                "successes": 0
            },
            {
                "name": "mouse_click_next", 
                "priority": 3, 
                "enabled": True,
                "success_rate": 0.0,
                "attempts": 0,
                "successes": 0
            },
            {
                "name": "combination_method", 
                "priority": 4, 
                "enabled": True,
                "success_rate": 0.0,
                "attempts": 0,
                "successes": 0
            },
            {
                "name": "external_macro", 
                "priority": 5, 
                "enabled": False,
                "success_rate": 0.0,
                "attempts": 0,
                "successes": 0
            }
        ]
        
        # C·∫•u h√¨nh
        self.config = {
            "max_retries": 5,
            "retry_delay": 0.3,
            "success_delay": 1.5,
            "focus_attempts": 3,
            "verification_enabled": True,
            "adaptive_timing": True
        }
        
        # Keywords
        self.live_keywords = [
            "LIVE", "Live", "live", 
            "TR·ª∞C TI·∫æP", "Tr·ª±c ti·∫øp", "tr·ª±c ti·∫øp",
            "ƒêANG LIVE", "ƒêang live",
            "PH√ÅT TR·ª∞C TI·∫æP", "Ph√°t tr·ª±c ti·∫øp"
        ]
        
        # Th·ªëng k√™
        self.stats = {
            "total_detections": 0,
            "total_successes": 0,
            "session_start": time.time()
        }
        
        print("‚úÖ Bot kh·ªüi t·∫°o th√†nh c√¥ng!")
    
    def find_tiktok_windows(self):
        """T√¨m c·ª≠a s·ªï TikTok v·ªõi filter t·ªët h∆°n"""
        if not self.modules['pygetwindow']:
            return []
        
        try:
            gw = self.modules['pygetwindow']
            all_windows = gw.getAllWindows()
            
            tiktok_windows = []
            for window in all_windows:
                title = window.title.lower()
                # M·ªü r·ªông criteria t√¨m ki·∫øm
                if any(keyword in title for keyword in ['tiktok', 'tik tok']) and \
                   window.width > 300 and window.height > 400 and \
                   window.visible:
                    tiktok_windows.append(window)
                    print(f"üéØ TikTok: {window.title} ({window.width}x{window.height})")
            
            return tiktok_windows
            
        except Exception as e:
            print(f"‚ùå L·ªói t√¨m c·ª≠a s·ªï: {e}")
            return []
    
    def ensure_window_focus(self, window, attempts=3):
        """ƒê·∫£m b·∫£o window ƒë∆∞·ª£c focus ƒë√∫ng c√°ch"""
        for attempt in range(attempts):
            try:
                # Bring to front
                window.restore()  # Restore if minimized
                window.activate()
                time.sleep(0.2)
                
                # Click v√†o gi·ªØa window ƒë·ªÉ ƒë·∫£m b·∫£o focus
                if self.modules['pyautogui']:
                    center_x = window.left + window.width // 2
                    center_y = window.top + window.height // 2
                    self.modules['pyautogui'].click(center_x, center_y)
                    time.sleep(0.1)
                
                # Verify focus b·∫±ng c√°ch ki·ªÉm tra active window
                gw = self.modules['pygetwindow']
                active_window = gw.getActiveWindow()
                if active_window and active_window.title == window.title:
                    print(f"‚úÖ Window focused successfully (attempt {attempt + 1})")
                    return True
                
                print(f"‚ö†Ô∏è Focus attempt {attempt + 1} failed, retrying...")
                time.sleep(0.3)
                
            except Exception as e:
                print(f"‚ùå Focus attempt {attempt + 1} error: {e}")
        
        print(f"‚ùå Failed to focus window after {attempts} attempts")
        return False
    
    def capture_screen(self, window):
        """Ch·ª•p m√†n h√¨nh v·ªõi error handling t·ªët h∆°n"""
        if not self.modules['pyautogui']:
            return None
        
        try:
            # Ensure focus first
            if not self.ensure_window_focus(window):
                return None
            
            pyautogui = self.modules['pyautogui']
            
            # Capture v·ªõi bounds checking
            left = max(0, window.left)
            top = max(0, window.top)
            width = min(window.width, 1920)  # Limit max width
            height = min(window.height, 1080)  # Limit max height
            
            screenshot = pyautogui.screenshot(region=(left, top, width, height))
            return cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)
            
        except Exception as e:
            print(f"‚ùå L·ªói ch·ª•p m√†n h√¨nh: {e}")
            return None
    
    def detect_live_text(self, image):
        """Ph√°t hi·ªán LIVE v·ªõi OCR c·∫£i thi·ªán"""
        if not self.modules['pytesseract']:
            return False, ""
        
        try:
            pytesseract = self.modules['pytesseract']
            
            # Preprocess image cho OCR t·ªët h∆°n
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Enhance contrast
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # Multiple OCR attempts v·ªõi configs kh√°c nhau
            configs = [
                '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz√Ä√Å√Ç√É√à√â√ä√å√ç√í√ì√î√ï√ô√ö√ù√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√ΩƒÇƒÉƒêƒëƒ®ƒ©≈®≈©∆†∆°∆Ø∆∞·∫†-·ªπ ',
                '--oem 3 --psm 8',
                '--oem 3 --psm 7'
            ]
            
            all_text = ""
            for config in configs:
                try:
                    text = pytesseract.image_to_string(enhanced, config=config, lang='vie+eng')
                    all_text += " " + text
                except:
                    continue
            
            # Check keywords
            for keyword in self.live_keywords:
                if keyword in all_text:
                    return True, keyword
            
            return False, ""
            
        except Exception as e:
            return False, ""
    
    def verify_skip_success(self, window, pre_screenshot):
        """Verify xem skip c√≥ th√†nh c√¥ng kh√¥ng"""
        if not self.config["verification_enabled"]:
            return True
        
        try:
            time.sleep(1.0)  # Wait for transition
            post_screenshot = self.capture_screen(window)
            
            if post_screenshot is None:
                return False
            
            # So s√°nh screenshots ƒë·ªÉ x√°c ƒë·ªãnh c√≥ thay ƒë·ªïi kh√¥ng
            if pre_screenshot is not None:
                # Convert to grayscale cho comparison
                pre_gray = cv2.cvtColor(pre_screenshot, cv2.COLOR_BGR2GRAY)
                post_gray = cv2.cvtColor(post_screenshot, cv2.COLOR_BGR2GRAY)
                
                # Calculate difference
                diff = cv2.absdiff(pre_gray, post_gray)
                diff_percentage = (cv2.countNonZero(diff) / (diff.shape[0] * diff.shape[1])) * 100
                
                # If >20% c·ªßa image thay ƒë·ªïi, coi nh∆∞ skip th√†nh c√¥ng
                if diff_percentage > 20:
                    print(f"‚úÖ Skip verified: {diff_percentage:.1f}% change detected")
                    return True
                else:
                    print(f"‚ùå Skip failed: only {diff_percentage:.1f}% change")
                    return False
            
            # Fallback: check if still live
            is_live, _ = self.detect_live_text(post_screenshot)
            success = not is_live
            
            if success:
                print("‚úÖ Skip verified: no more LIVE detected")
            else:
                print("‚ùå Skip failed: still detecting LIVE")
            
            return success
            
        except Exception as e:
            print(f"‚ùå Verification error: {e}")
            return False
    
    # Skip Methods
    def skip_method_enhanced_keyboard(self, window, screenshot):
        """Enhanced keyboard method v·ªõi multiple approaches"""
        if not self.modules['pyautogui']:
            return False
        
        try:
            pyautogui = self.modules['pyautogui']
            
            # Ensure strong focus
            if not self.ensure_window_focus(window, attempts=2):
                return False
            
            # Try multiple keyboard combinations
            methods = [
                lambda: pyautogui.press('down'),
                lambda: pyautogui.press('space'),
                lambda: pyautogui.press('right'),
                lambda: [pyautogui.press('space'), time.sleep(0.2), pyautogui.press('down')],
                lambda: [pyautogui.keyDown('down'), time.sleep(0.1), pyautogui.keyUp('down')]
            ]
            
            for i, method in enumerate(methods):
                print(f"   üîÑ Keyboard method {i+1}")
                
                # Re-focus before each attempt
                window.activate()
                time.sleep(0.1)
                
                # Execute method
                if callable(method):
                    method()
                else:
                    for action in method:
                        if callable(action):
                            action()
                        else:
                            time.sleep(action)
                
                # Quick verification
                time.sleep(0.5)
                if self.verify_skip_success(window, screenshot):
                    print(f"   ‚úÖ Keyboard method {i+1} successful")
                    return True
                
                print(f"   ‚ùå Keyboard method {i+1} failed")
                time.sleep(0.2)
            
            return False
            
        except Exception as e:
            print(f"‚ùå Enhanced keyboard error: {e}")
            return False
    
    def skip_method_mouse_swipe_up(self, window, screenshot):
        """Mouse swipe up method v·ªõi variations"""
        if not self.modules['pyautogui']:
            return False
        
        try:
            pyautogui = self.modules['pyautogui']
            
            if not self.ensure_window_focus(window):
                return False
            
            # Calculate swipe coordinates
            center_x = window.left + window.width // 2
            center_y = window.top + window.height // 2
            
            # Try different swipe patterns
            swipe_patterns = [
                # Pattern 1: Normal swipe
                {
                    "start_y": center_y + 150,
                    "end_y": center_y - 150,
                    "duration": 0.3
                },
                # Pattern 2: Longer swipe
                {
                    "start_y": center_y + 200,
                    "end_y": center_y - 200, 
                    "duration": 0.4
                },
                # Pattern 3: Quick swipe
                {
                    "start_y": center_y + 100,
                    "end_y": center_y - 100,
                    "duration": 0.2
                }
            ]
            
            for i, pattern in enumerate(swipe_patterns):
                print(f"   üîÑ Swipe pattern {i+1}")
                
                # Ensure focus
                pyautogui.click(center_x, center_y)
                time.sleep(0.1)
                
                # Perform swipe
                pyautogui.drag(
                    center_x, pattern["start_y"],
                    center_x, pattern["end_y"],
                    duration=pattern["duration"]
                )
                
                # Verification
                time.sleep(0.7)
                if self.verify_skip_success(window, screenshot):
                    print(f"   ‚úÖ Swipe pattern {i+1} successful")
                    return True
                
                print(f"   ‚ùå Swipe pattern {i+1} failed")
                time.sleep(0.3)
            
            return False
            
        except Exception as e:
            print(f"‚ùå Mouse swipe error: {e}")
            return False
    
    def skip_method_mouse_click_next(self, window, screenshot):
        """Click v√†o v·ªã tr√≠ n√∫t next (n·∫øu c√≥)"""
        if not self.modules['pyautogui']:
            return False
        
        try:
            pyautogui = self.modules['pyautogui']
            
            if not self.ensure_window_focus(window):
                return False
            
            # Possible next button locations (relative to window)
            click_positions = [
                # Right side (common for next buttons)
                (window.left + window.width - 50, window.top + window.height // 2),
                # Bottom right
                (window.left + window.width - 100, window.top + window.height - 100),
                # Center right
                (window.left + window.width - 30, window.top + window.height // 2),
                # Bottom center (swipe area)
                (window.left + window.width // 2, window.top + window.height - 50)
            ]
            
            for i, (x, y) in enumerate(click_positions):
                print(f"   üîÑ Click position {i+1}")
                
                # Click position
                pyautogui.click(x, y)
                time.sleep(0.3)
                
                # Verification
                if self.verify_skip_success(window, screenshot):
                    print(f"   ‚úÖ Click position {i+1} successful")
                    return True
                
                print(f"   ‚ùå Click position {i+1} failed")
                time.sleep(0.2)
            
            return False
            
        except Exception as e:
            print(f"‚ùå Mouse click error: {e}")
            return False
    
    def skip_method_combination_method(self, window, screenshot):
        """Combination c·ªßa nhi·ªÅu methods"""
        print("   üîÑ Trying combination method")
        
        try:
            # Combination 1: Click + Keyboard
            if self.modules['pyautogui']:
                pyautogui = self.modules['pyautogui']
                
                # Focus + Click center
                if self.ensure_window_focus(window):
                    center_x = window.left + window.width // 2
                    center_y = window.top + window.height // 2
                    
                    pyautogui.click(center_x, center_y)
                    time.sleep(0.1)
                    pyautogui.press('down')
                    time.sleep(0.5)
                    
                    if self.verify_skip_success(window, screenshot):
                        print("   ‚úÖ Combination method successful")
                        return True
            
            # Combination 2: Multiple swipes
            if self.modules['pyautogui']:
                center_x = window.left + window.width // 2
                center_y = window.top + window.height // 2
                
                # Small swipe + big swipe
                pyautogui.drag(center_x, center_y + 50, center_x, center_y - 50, duration=0.1)
                time.sleep(0.1)
                pyautogui.drag(center_x, center_y + 150, center_x, center_y - 150, duration=0.3)
                time.sleep(0.7)
                
                if self.verify_skip_success(window, screenshot):
                    print("   ‚úÖ Combination method successful") 
                    return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Combination method error: {e}")
            return False
    
    def skip_method_external_macro(self, window, screenshot):
        """External macro method"""
        # Implementation t∆∞∆°ng t·ª± nh∆∞ tr∆∞·ªõc
        return False
    
    def update_method_stats(self, method, success):
        """Update statistics cho method"""
        method["attempts"] += 1
        if success:
            method["successes"] += 1
        
        # Calculate success rate
        if method["attempts"] > 0:
            method["success_rate"] = method["successes"] / method["attempts"]
    
    def get_best_methods(self):
        """Get methods sorted by success rate"""
        enabled_methods = [m for m in self.skip_methods if m["enabled"]]
        
        # Sort by success rate (descending), then by priority
        return sorted(enabled_methods, 
                     key=lambda x: (-x["success_rate"], x["priority"]))
    
    def skip_with_smart_selection(self, window):
        """Skip v·ªõi smart method selection"""
        self.stats["total_detections"] += 1
        
        # Capture screenshot for verification
        screenshot = self.capture_screen(window)
        if screenshot is None:
            return False
        
        # Get best methods
        methods = self.get_best_methods()
        
        if not methods:
            print("‚ùå Kh√¥ng c√≥ method n√†o ƒë∆∞·ª£c k√≠ch ho·∫°t")
            return False
        
        print(f"üéØ Th·ª≠ {len(methods)} methods theo th·ª© t·ª± hi·ªáu qu·∫£...")
        
        for attempt in range(self.config["max_retries"]):
            print(f"\nüîÑ L·∫ßn th·ª≠ {attempt + 1}/{self.config['max_retries']}")
            
            for method in methods:
                method_name = method["name"]
                success_rate = method["success_rate"] * 100
                
                print(f"‚ö° Method: {method_name} (success rate: {success_rate:.1f}%)")
                
                # Get method function
                method_func = getattr(self, f"skip_method_{method_name}", None)
                if not method_func:
                    continue
                
                # Execute method
                start_time = time.time()
                success = method_func(window, screenshot)
                execution_time = time.time() - start_time
                
                # Update stats
                self.update_method_stats(method, success)
                
                print(f"   ‚è±Ô∏è Execution time: {execution_time:.2f}s")
                
                if success:
                    self.stats["total_successes"] += 1
                    print(f"‚úÖ SKIP TH√ÄNH C√îNG b·∫±ng {method_name}!")
                    time.sleep(self.config["success_delay"])
                    return True
                else:
                    print(f"‚ùå {method_name} failed")
                
                # Adaptive delay based on success rate
                if self.config["adaptive_timing"]:
                    delay = self.config["retry_delay"] * (1 + (1 - method["success_rate"]))
                    time.sleep(min(delay, 1.0))
                else:
                    time.sleep(self.config["retry_delay"])
            
            # Delay between retry attempts
            if attempt < self.config["max_retries"] - 1:
                print(f"‚è≥ Ch·ªù tr∆∞·ªõc l·∫ßn th·ª≠ ti·∫øp theo...")
                time.sleep(0.5)
        
        print(f"‚ùå T·∫§T C·∫¢ METHODS ƒê·ªÄU TH·∫§T B·∫†I sau {self.config['max_retries']} l·∫ßn th·ª≠")
        return False
    
    def test_eye_movement_system(self):
        """Test h·ªá th·ªëng chuy·ªÉn ƒë·ªông m·∫Øt"""
        print("\nüëÅÔ∏è TESTING EYE MOVEMENT SYSTEM")
        print("=" * 50)
        
        self.eye_movement.start_animation()
        
        try:
            print("üîÑ Testing various eye movement patterns...")
            
            # Test 1: Basic gaze patterns
            print("\n1. Testing basic gaze patterns...")
            gaze_patterns = [
                (0.0, 0.0),      # Center
                (0.7, 0.0),      # Right
                (-0.7, 0.0),     # Left  
                (0.0, 0.5),      # Up
                (0.0, -0.5),     # Down
                (0.5, 0.3),      # Top-right
                (-0.5, -0.3),    # Bottom-left
            ]
            
            for i, (x, y) in enumerate(gaze_patterns):
                print(f"   Pattern {i+1}: Gaze to ({x}, {y})")
                self.eye_movement.set_gaze_target(x, y)
                
                # Simulate animation for 2 seconds
                for _ in range(20):  # 10 FPS for 2 seconds
                    self.eye_movement.update_animation_frame()
                    eye_data = self.eye_movement.get_eye_data()
                    time.sleep(0.1)
                
                current_gaze = eye_data['gaze']
                print(f"   Current gaze: ({current_gaze['x']:.2f}, {current_gaze['y']:.2f})")
            
            # Test 2: Natural behaviors
            print("\n2. Testing natural behaviors (10 seconds)...")
            start_time = time.time()
            frame_count = 0
            
            while time.time() - start_time < 10:
                self.eye_movement.update_animation_frame()
                frame_count += 1
                
                if frame_count % 20 == 0:  # Every 2 seconds
                    eye_data = self.eye_movement.get_eye_data()
                    print(f"   Frame {frame_count}: Gaze({eye_data['gaze']['x']:.2f}, {eye_data['gaze']['y']:.2f}) "
                          f"Pupil:{eye_data['pupil_dilation']:.2f} Blink:{eye_data['blink_state']:.2f}")
                
                time.sleep(0.1)
            
            # Test 3: Forced blinks
            print("\n3. Testing forced blinks...")
            for i in range(3):
                print(f"   Blink {i+1}")
                self.eye_movement.trigger_natural_blink()
                time.sleep(1)
            
            # Test 4: Attention simulation
            print("\n4. Testing attention simulation...")
            print("   Simulating high attention...")
            self.eye_movement.current_state["attention_level"] = 1.0
            self.eye_movement.set_gaze_target(0.0, 0.0)
            
            for _ in range(20):
                self.eye_movement.update_animation_frame()
                time.sleep(0.1)
            
            print("   Simulating low attention...")
            self.eye_movement.current_state["attention_level"] = 0.3
            
            for _ in range(20):
                self.eye_movement.update_animation_frame()
                time.sleep(0.1)
            
            print("\n‚úÖ Eye movement test completed successfully!")
            self.eye_movement.print_eye_stats()
            
        except KeyboardInterrupt:
            print("\nüõë Test interrupted by user")
        finally:
            self.eye_movement.stop_animation()
            
        input("\nPress Enter to return to main menu...")

    def print_detailed_stats(self):
        """In th·ªëng k√™ chi ti·∫øt"""
        print("\n" + "="*60)
        print("üìä TH·ªêNG K√ä CHI TI·∫æT")
        print("="*60)
        
        # Overall stats
        runtime = time.time() - self.stats["session_start"]
        hours = int(runtime // 3600)
        minutes = int((runtime % 3600) // 60)
        
        print(f"‚è∞ Th·ªùi gian ch·∫°y: {hours}h {minutes}m")
        print(f"üéØ T·ªïng ph√°t hi·ªán LIVE: {self.stats['total_detections']}")
        print(f"‚úÖ Skip th√†nh c√¥ng: {self.stats['total_successes']}")
        
        if self.stats['total_detections'] > 0:
            overall_rate = (self.stats['total_successes'] / self.stats['total_detections']) * 100
            print(f"üìà T·ª∑ l·ªá th√†nh c√¥ng t·ªïng: {overall_rate:.1f}%")
        
        print(f"\nüìã CHI TI·∫æT THEO METHOD:")
        print("-" * 60)
        
        for method in sorted(self.skip_methods, key=lambda x: -x["success_rate"]):
            if method["attempts"] > 0:
                rate = method["success_rate"] * 100
                status = "üü¢" if method["enabled"] else "üî¥"
                print(f"{status} {method['name']:<20} | "
                      f"{method['successes']:>3}/{method['attempts']:<3} | "
                      f"{rate:>6.1f}% | "
                      f"Priority: {method['priority']}")
        
        print("="*60)
    
    def start_monitoring(self):
        """B·∫Øt ƒë·∫ßu gi√°m s√°t v·ªõi improved logic v√† eye movement"""
        print("üîç B·∫Øt ƒë·∫ßu gi√°m s√°t TikTok v·ªõi Smart Skip Selection v√† Realistic Eye Movement...")
        print("‚ö†Ô∏è Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng")
        
        # Start eye movement animation
        self.eye_movement.start_animation()
        
        cycle = 0
        consecutive_failures = 0
        
        try:
            while True:
                cycle += 1
                print(f"\n{'='*20} Chu k·ª≥ #{cycle} {'='*20}")
                
                # Update eye movement animation
                self.eye_movement.update_animation_frame()
                
                # Show current eye state every 10 cycles
                if cycle % 10 == 0:
                    eye_data = self.eye_movement.get_eye_data()
                    print(f"üëÅÔ∏è Gaze: ({eye_data['gaze']['x']:.2f}, {eye_data['gaze']['y']:.2f}) | "
                          f"Pupil: {eye_data['pupil_dilation']:.2f} | "
                          f"Attention: {eye_data['attention_level']:.2f}")
                
                windows = self.find_tiktok_windows()
                
                if not windows:
                    print("‚è≥ Kh√¥ng t√¨m th·∫•y TikTok...")
                    consecutive_failures += 1
                    
                    # Update eye movement to show boredom/waiting
                    self.eye_movement.set_gaze_target(
                        random.uniform(-0.5, 0.5), 
                        random.uniform(-0.3, 0.3)
                    )
                    
                    # Adaptive delay based on failures
                    delay = min(3 + consecutive_failures, 10)
                    print(f"‚è≥ Ch·ªù {delay}s...")
                    
                    # Continue eye animation during wait
                    for _ in range(delay * 2):  # 2 updates per second
                        self.eye_movement.update_animation_frame()
                        time.sleep(0.5)
                    continue
                
                consecutive_failures = 0  # Reset counter
                
                for i, window in enumerate(windows):
                    print(f"\nüîç Window {i+1}/{len(windows)}: {window.title}")
                    
                    # Update eye movement to show attention to window
                    window_attention_x = random.uniform(-0.3, 0.3)
                    window_attention_y = random.uniform(-0.2, 0.2)
                    self.eye_movement.set_gaze_target(window_attention_x, window_attention_y)
                    
                    screenshot = self.capture_screen(window)
                    if screenshot is None:
                        print("‚ö†Ô∏è Kh√¥ng th·ªÉ ch·ª•p m√†n h√¨nh")
                        # Show confusion in eye movement
                        self.eye_movement.set_gaze_target(
                            random.uniform(-0.8, 0.8),
                            random.uniform(-0.4, 0.4)
                        )
                        continue
                    
                    is_live, keyword = self.detect_live_text(screenshot)
                    
                    if is_live:
                        print(f"üî¥ PH√ÅT HI·ªÜN LIVE! Keyword: '{keyword}'")
                        
                        # Show focused attention in eye movement
                        self.eye_movement.current_state["attention_level"] = 1.0
                        self.eye_movement.set_gaze_target(0.0, 0.0)  # Focus center
                        
                        success = self.skip_with_smart_selection(window)
                        
                        if success:
                            print("üéâ Skip th√†nh c√¥ng!")
                            # Show satisfaction/relief in eye movement
                            self.eye_movement.trigger_natural_blink()
                            self.eye_movement.set_gaze_target(
                                random.uniform(-0.2, 0.2),
                                random.uniform(-0.2, 0.2)
                            )
                        else:
                            print("üòû Skip th·∫•t b·∫°i!")
                            # Show frustration in eye movement
                            self.eye_movement.set_gaze_target(
                                random.uniform(-0.6, 0.6),
                                random.uniform(-0.4, 0.4),
                                speed_multiplier=1.5
                            )
                    else:
                        print("‚úÖ Kh√¥ng ph·∫£i live")
                        # Relaxed eye movement
                        self.eye_movement.set_gaze_target(
                            random.uniform(-0.4, 0.4),
                            random.uniform(-0.3, 0.3)
                        )
                
                print("‚è≥ Ch·ªù 3 gi√¢y tr∆∞·ªõc chu k·ª≥ ti·∫øp theo...")
                
                # Continue eye animation during wait
                for _ in range(6):  # 6 updates over 3 seconds
                    self.eye_movement.update_animation_frame()
                    time.sleep(0.5)
                
        except KeyboardInterrupt:
            print("\nüõë D·ª´ng bot theo y√™u c·∫ßu ng∆∞·ªùi d√πng")
            self.eye_movement.stop_animation()
            self.print_detailed_stats()
            self.eye_movement.print_eye_stats()

def main():
    """Main function"""
    print("=" * 70)
    print("ü§ñ TikTok Bot - IMPROVED VERSION v·ªõi EYE MOVEMENT EXTENSION")
    print("üìà Smart Skip Selection v·ªõi Success Rate Tracking")
    print("üëÅÔ∏è  Realistic Eye Movement Animation cho Background")
    print("=" * 70)
    
    try:
        bot = ImprovedTikTokBot()
        
        while True:
            print("\nüéØ MENU:")
            print("1. B·∫Øt ƒë·∫ßu gi√°m s√°t")
            print("2. Xem th·ªëng k√™ chi ti·∫øt")
            print("3. Test Eye Movement System")
            print("4. C·∫•u h√¨nh")
            print("5. Tho√°t")
            
            choice = input("Ch·ªçn (1-5): ").strip()
            
            if choice == "1":
                bot.start_monitoring()
            elif choice == "2":
                bot.print_detailed_stats()
                bot.eye_movement.print_eye_stats()
            elif choice == "3":
                bot.test_eye_movement_system()
            elif choice == "4":
                print("üîß C·∫•u h√¨nh s·∫Ω ƒë∆∞·ª£c th√™m trong phi√™n b·∫£n ti·∫øp theo")
            elif choice == "5":
                print("üëã T·∫°m bi·ªát!")
                break
            else:
                print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
    
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")

if __name__ == "__main__":
    main()
